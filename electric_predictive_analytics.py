# -*- coding: utf-8 -*-
"""Electric Predictive Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RisUij-IEdeBasrIVKwhoMAZM4WjxBw_
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Dense

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import AdaBoostRegressor
from sklearn.ensemble import RandomForestRegressor

import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

# Username dan key Kaggle API
os.environ['KAGGLE_USERNAME'] = 'harsharockerzzz'
os.environ['KAGGLE_KEY']      = 'a8e4f9fb54ac2207cd357492d8403803'

# Download dataset dari Kaggle
!kaggle datasets download -d fedesoriano/electric-power-consumption -f powerconsumption.csv

epower = pd.read_csv('powerconsumption.csv.zip')
epower.head()

epower.drop('GeneralDiffuseFlows', inplace=True, axis=1)
epower.drop('DiffuseFlows',        inplace=True, axis=1)

epower.Datetime = pd.to_datetime(epower.Datetime)
epower

epower['Year']   = epower['Datetime'].apply(lambda date: date.year)
epower['Month']  = epower['Datetime'].apply(lambda date: date.month)
epower['Day']    = epower['Datetime'].apply(lambda date: date.day)
epower['Hour']   = epower['Datetime'].apply(lambda date: date.hour)
epower['Minute'] = epower['Datetime'].apply(lambda date: date.minute)

epower.drop('Datetime', inplace=True, axis=1)

epower.head()

epower.info()

epower.describe()

epower.isnull().sum()

fig, axes = plt.subplots(2, 3, figsize=(14, 7))

sns.boxplot(ax=axes[0, 0], x=epower.Temperature)
sns.boxplot(ax=axes[0, 1], x=epower.Humidity)
sns.boxplot(ax=axes[0, 2], x=epower.WindSpeed)

sns.boxplot(ax=axes[1, 0], x=epower.PowerConsumption_Zone1)
sns.boxplot(ax=axes[1, 1], x=epower.PowerConsumption_Zone2)
sns.boxplot(ax=axes[1, 2], x=epower.PowerConsumption_Zone3)

Q1 = epower.quantile(0.25)
Q3 = epower.quantile(0.75)

IQR = Q3 - Q1

epower = epower[~((epower < (Q1 - 1.5*IQR)) | (epower > (Q3 + 1.5*IQR))).any(axis=1)]

epower.shape

fig, axes = plt.subplots(2, 3, figsize=(14, 7))

sns.boxplot(ax=axes[0, 0], x=epower.Temperature)
sns.boxplot(ax=axes[0, 1], x=epower.Humidity)
sns.boxplot(ax=axes[0, 2], x=epower.WindSpeed)

sns.boxplot(ax=axes[1, 0], x=epower.PowerConsumption_Zone1)
sns.boxplot(ax=axes[1, 1], x=epower.PowerConsumption_Zone2)
sns.boxplot(ax=axes[1, 2], x=epower.PowerConsumption_Zone3)

epower.hist(bins=50, figsize=(14, 12))
plt.show()

sns.pairplot(epower, diag_kind='kde')

plt.figure(figsize = (10, 8))
correlationMatrix = epower.corr().round(2)

sns.heatmap(
    data       = correlationMatrix,
    vmin       = -1,
    vmax       = 1,
    cmap       = 'coolwarm',
    annot      = True,
    linewidths = 0.5
)

plt.title('Correlation Matrix untuk Fitur Numerik', size=20)

epower.drop(['WindSpeed'], inplace=True, axis=1)
epower.drop(['Year'],      inplace=True, axis=1)
epower.drop(['Day'],       inplace=True, axis=1)
epower.drop(['Minute'],    inplace=True, axis=1)
epower

x = epower.drop(['PowerConsumption_Zone1', 'PowerConsumption_Zone2', 'PowerConsumption_Zone3'], axis=1)
y = epower['PowerConsumption_Zone2']

xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size=0.1, random_state=123)

print(f'Total seluruh sampel : {len(x)}')
print(f'Total data train     : {len(xTrain)}')
print(f'Total data test      : {len(xTest)}')

numericalFeatures = ['Temperature', 'Humidity', 'Month', 'Hour']

scaler = StandardScaler()
scaler.fit(xTrain[numericalFeatures])
xTrain[numericalFeatures] = scaler.transform(xTrain.loc[:, numericalFeatures])
xTrain[numericalFeatures].head()

xTrain[numericalFeatures].describe().round(4)

models = pd.DataFrame(
    index   = ['train_mse', 'test_mse'],
    columns = ['KNN', 'RandomForest', 'Boosting']
)

"""## 5.2 K-Nearest Neighbor (KNN) Algorithm"""

knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(xTrain, yTrain)

models.loc['train_mse', 'knn'] = mean_squared_error(y_pred=knn.predict(xTrain), y_true=yTrain)

"""## 5.3 Random Forest Algorithm"""

rf = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
rf.fit(xTrain, yTrain)

models.loc['train_mse', 'RandomForest'] = mean_squared_error(y_pred=rf.predict(xTrain), y_true=yTrain)

"""## 5.4 Adaptive Boosting (AdaBoost) Algorithm"""

boosting = AdaBoostRegressor(learning_rate=0.05, random_state=55)
boosting.fit(xTrain, yTrain)

models.loc['train_mse', 'Boosting'] = mean_squared_error(y_pred=boosting.predict(xTrain), y_true = yTrain)

"""# **6. *Model Evaluation***"""

xTest.loc[:, numericalFeatures] = scaler.transform(xTest[numericalFeatures])

mse = pd.DataFrame(columns=['train', 'test'], index=['KNN', 'RF', 'Boosting'])

modelDict = {
    'KNN'     : knn,
    'RF'      : rf,
    'Boosting': boosting
}

for name, model in modelDict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=yTrain, y_pred=model.predict(xTrain))/1e3
    mse.loc[name, 'test']  = mean_squared_error(y_true=yTest,  y_pred=model.predict(xTest))/1e3

mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

prediksi  = xTest.iloc[:1].copy()
pred_dict = {'y_true': yTest[:1]}

for name, model in modelDict.items():
    pred_dict['prediksi_' + name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)